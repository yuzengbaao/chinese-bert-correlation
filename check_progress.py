#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ£€æŸ¥æ•°æ®é‡‡é›†è¿›åº¦
"""

import os
import json

def check_progress():
    """æ£€æŸ¥æ•°æ®é‡‡é›†è¿›åº¦"""
    
    dataset_file = 'large_wikipedia_dataset.json'
    
    if os.path.exists(dataset_file):
        try:
            with open(dataset_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            sentences = data.get('sentences', [])
            vocab = data.get('vocab', [])
            
            print(f"âœ… å½“å‰å¥å­æ•°: {len(sentences):,}")
            print(f"âœ… å½“å‰è¯æ±‡æ•°: {len(vocab):,}")
            print(f"ğŸ“Š å®Œæˆåº¦: {len(sentences)/100000*100:.1f}%")
            
            if len(sentences) >= 100000:
                print("ğŸ‰ æ•°æ®é‡‡é›†å·²å®Œæˆï¼")
                return True
            else:
                print(f"â³ è¿˜éœ€: {100000-len(sentences):,} å¥å­")
                return False
        except:
            print("âš ï¸  æ–‡ä»¶æ­£åœ¨å†™å…¥ä¸­...")
            return False
    else:
        print("â³ æ•°æ®é‡‡é›†è¿›è¡Œä¸­ï¼Œæ–‡ä»¶å°šæœªç”Ÿæˆ...")
        return False

if __name__ == '__main__':
    check_progress()
