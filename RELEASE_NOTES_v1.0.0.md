# Chinese BERT 100K Training Correlation Study - v1.0.0

**é¦–æ¬¡æ­£å¼å‘å¸ƒ | First Official Release**

å‘å¸ƒæ—¥æœŸ: 2025å¹´10æœˆ17æ—¥ | Release Date: October 17, 2025

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿° | Project Overview

æœ¬é¡¹ç›®æ·±å…¥ç ”ç©¶ä¸­æ–‡BERTæ¨¡å‹è®­ç»ƒæ­¥æ•°ä¸é®è”½è¯­è¨€æ¨¡å‹ï¼ˆMLMï¼‰å‡†ç¡®ç‡ä¹‹é—´çš„ç›¸å…³æ€§ã€‚é€šè¿‡100,000æ­¥çš„ç³»ç»Ÿè®­ç»ƒå’Œä¸¥æ ¼çš„ç»Ÿè®¡åˆ†æï¼Œè¯å®äº†äºŒè€…ä¹‹é—´å­˜åœ¨**å¼ºæ­£ç›¸å…³å…³ç³»** (r=0.7869)ã€‚

This project investigates the correlation between training steps and Masked Language Modeling (MLM) accuracy in Chinese BERT models. Through 100,000 systematic training steps and rigorous statistical analysis, we confirmed a **strong positive correlation** (r=0.7869).

---

## ğŸ“Š æ ¸å¿ƒæˆæœ | Key Results

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **Pearson r** | 0.7869 | å¼ºæ­£ç›¸å…³ (ç›®æ ‡0.85çš„92.6%) |
| **RÂ²** | 0.6193 | è§£é‡Š61.9%çš„æ–¹å·® |
| **P-value** | < 0.001 | ææ˜¾è‘—ç»Ÿè®¡å­¦æ„ä¹‰ |
| **MLMå‡†ç¡®ç‡** | 50.53% | å¹³å‡å‡†ç¡®ç‡ï¼Œæœ€é«˜66.35% |
| **æŸå¤±é™ä½** | 66.8% | ä»8.96é™è‡³2.97 |
| **è®­ç»ƒæ­¥æ•°** | 100,000 | å®Œæ•´è®­ç»ƒå‘¨æœŸ |
| **è®­ç»ƒæ—¶é—´** | 22.5å°æ—¶ | RTX 3070 GPU |

---

## ğŸ‰ ä¸»è¦ç‰¹æ€§ | Main Features

### 1. å®Œæ•´çš„è®­ç»ƒæµç¨‹
- âœ… 100Kæ­¥ç³»ç»ŸåŒ–è®­ç»ƒ
- âœ… åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦ï¼ˆé¢„çƒ­+ä½™å¼¦è¡°å‡ï¼‰
- âœ… å¤šé˜¶æ®µæ£€æŸ¥ç‚¹ä¿å­˜
- âœ… å®æ—¶è®­ç»ƒç›‘æ§

### 2. ä¸¥æ ¼çš„ç»Ÿè®¡åˆ†æ
- âœ… Pearsonç›¸å…³ç³»æ•°è®¡ç®—
- âœ… 95%ç½®ä¿¡åŒºé—´ [0.76, 0.81]
- âœ… RÂ²å†³å®šç³»æ•°åˆ†æ
- âœ… æ®‹å·®å’Œæ˜¾è‘—æ€§æ£€éªŒ

### 3. ä¸°å¯Œçš„æ•°æ®é›†
- âœ… 325,537æ¡ä¸­æ–‡å¥å­
- âœ… 10,049è¯æ±‡é‡
- âœ… 59ä¸ªä¸“ä¸šé¢†åŸŸè¦†ç›–
- âœ… é«˜è´¨é‡æ•°æ®æ¸…æ´—

### 4. ä¸“ä¸šå¯è§†åŒ–
- âœ… è®­ç»ƒæ›²çº¿å›¾ï¼ˆ4åˆ1ï¼‰
- âœ… ç›¸å…³æ€§åˆ†æå›¾
- âœ… 50K vs 100Kå¯¹æ¯”
- âœ… æŸå¤±å‡½æ•°æ¼”å˜

### 5. å®Œå–„çš„æ–‡æ¡£
- âœ… åŒè¯­README
- âœ… æ•°æ®é›†è¯¦ç»†è¯´æ˜
- âœ… è®­ç»ƒæŒ‡å—ï¼ˆ520è¡Œï¼‰
- âœ… åˆ†ææ–¹æ³•è®ºï¼ˆ660è¡Œï¼‰
- âœ… 4ä¸ªä½¿ç”¨ç¤ºä¾‹

---

## ğŸ“¦ å‘å¸ƒå†…å®¹ | Release Contents

### æ ¸å¿ƒæ–‡ä»¶ | Core Files
- `stage4_large_100k_final.pth` - æœ€ç»ˆè®­ç»ƒæ¨¡å‹ï¼ˆ48.40Må‚æ•°ï¼‰
- `training_history_100k.json` - å®Œæ•´è®­ç»ƒå†å²ï¼ˆ1000ä¸ªæ•°æ®ç‚¹ï¼‰
- `analysis_100k_result.json` - ç»Ÿè®¡åˆ†æç»“æœ

### è®­ç»ƒè„šæœ¬ | Training Scripts
- `main_train.py` - ä¸»è®­ç»ƒè„šæœ¬
- `analyze_100k.py` - ç»“æœåˆ†æå·¥å…·
- `visualize_results.py` - å¯è§†åŒ–ç”Ÿæˆå™¨

### æ–‡æ¡£ | Documentation
- `README.md` - é¡¹ç›®ä¸»é¡µï¼ˆåŒè¯­ï¼‰
- `docs/DATASET.md` - æ•°æ®é›†è¯´æ˜ï¼ˆ278è¡Œï¼‰
- `docs/TRAINING.md` - è®­ç»ƒæŒ‡å—ï¼ˆ520è¡Œï¼‰
- `docs/ANALYSIS.md` - åˆ†ææ–¹æ³•è®ºï¼ˆ660è¡Œï¼‰
- `CHANGELOG.md` - ç‰ˆæœ¬å†å²

### ç¤ºä¾‹ä»£ç  | Examples
- `examples/quick_start.py` - å¿«é€Ÿå¼€å§‹
- `examples/load_and_analyze.py` - è‡ªå®šä¹‰åˆ†æ
- `examples/prepare_dataset.py` - æ•°æ®å‡†å¤‡
- `examples/README.md` - ç¤ºä¾‹æŒ‡å—

### å¯è§†åŒ– | Visualizations
- `results/training_curves.png` - è®­ç»ƒæ›²çº¿ï¼ˆ780 KBï¼‰
- `results/correlation_analysis.png` - ç›¸å…³æ€§åˆ†æï¼ˆ1.06 MBï¼‰
- `results/comparison_50k_100k.png` - å¯¹æ¯”å›¾ï¼ˆ157 KBï¼‰
- `results/loss_analysis.png` - æŸå¤±åˆ†æï¼ˆ577 KBï¼‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ | Quick Start

### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/yuzengbaao/chinese-bert-correlation.git
cd chinese-bert-correlation
```

### 2. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 3. è¿è¡Œç¤ºä¾‹
```bash
# æµ‹è¯•æ¨¡å‹é¢„æµ‹
python examples/quick_start.py

# åˆ†æè®­ç»ƒç»“æœ
python examples/load_and_analyze.py
```

### 4. æŸ¥çœ‹ç»“æœ
- æ‰“å¼€ `results/` ç›®å½•æŸ¥çœ‹å¯è§†åŒ–å›¾è¡¨
- é˜…è¯» `analysis_100k_result.json` æŸ¥çœ‹è¯¦ç»†æŒ‡æ ‡

---

## ğŸ“ˆ ä¸50Kè®­ç»ƒå¯¹æ¯” | Comparison with 50K Training

| æŒ‡æ ‡ | 50Kè®­ç»ƒ | 100Kè®­ç»ƒ | æå‡ |
|------|---------|----------|------|
| Pearson r | 0.6355 | 0.7869 | +23.8% âœ… |
| RÂ² | 0.4038 | 0.6193 | +53.4% âœ… |
| MLMå‡†ç¡®ç‡ | 14.50% | 50.53% | +248.5% âœ… |
| æœ€å¤§å‡†ç¡®ç‡ | 31.88% | 66.35% | +108.0% âœ… |
| æŸå¤± | 5.12 | 2.97 | -42.0% âœ… |

---

## ğŸ“ å­¦æœ¯å¼•ç”¨ | Citation

å¦‚æœæœ¬é¡¹ç›®å¯¹ä½ çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{chinese_bert_correlation_2025,
  author = {Your Name},
  title = {Chinese BERT 100K Training Correlation Study},
  year = {2025},
  publisher = {GitHub},
  version = {v1.0.0},
  url = {https://github.com/yuzengbaao/chinese-bert-correlation},
  note = {Pearson r = 0.7869, MLM accuracy = 50.53\%}
}
```

---

## ğŸ’¡ åº”ç”¨åœºæ™¯ | Applications

1. **æ¨¡å‹è®­ç»ƒç­–ç•¥** - æ ¹æ®ç›¸å…³æ€§ä¼˜åŒ–è®­ç»ƒè®¡åˆ’
2. **LLMç›‘æ§ç³»ç»Ÿ** - å®æ—¶è¯„ä¼°è®­ç»ƒè¿›åº¦
3. **æ•™è‚²ç ”ç©¶** - æ·±åº¦å­¦ä¹ è¯¾ç¨‹æ¡ˆä¾‹
4. **æˆæœ¬ä¼˜åŒ–** - é¢„æµ‹è®­ç»ƒæ—¶é—´å’Œèµ„æºéœ€æ±‚
5. **AutoMLé›†æˆ** - è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
6. **æ¨¡å‹å‹ç¼©** - æŒ‡å¯¼çŸ¥è¯†è’¸é¦ç­–ç•¥

---

## ğŸ”§ æŠ€æœ¯æ ˆ | Tech Stack

- **æ·±åº¦å­¦ä¹ **: PyTorch 2.0+, Transformers 4.30+
- **NLPå·¥å…·**: BERT, jieba
- **æ•°æ®åˆ†æ**: NumPy, SciPy, Pandas
- **å¯è§†åŒ–**: Matplotlib, Seaborn
- **æ•°æ®é›†**: 325Kä¸­æ–‡ç»´åŸºç™¾ç§‘å¥å­

---

## ğŸ“ æ›´æ–°æ—¥å¿— | Changelog

æŸ¥çœ‹ [CHANGELOG.md](CHANGELOG.md) äº†è§£è¯¦ç»†æ›´æ–°å†å²ã€‚

---

## ğŸ¤ è´¡çŒ® | Contributing

æ¬¢è¿è´¡çŒ®ï¼è¯·é˜…è¯» [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è´¡çŒ®æŒ‡å—ã€‚

å¯èƒ½çš„è´¡çŒ®æ–¹å‘ï¼š
- ğŸ”¬ æ‰©å±•åˆ°200K+è®­ç»ƒæ­¥æ•°
- ğŸ“Š å¢åŠ æ›´å¤šç»Ÿè®¡åˆ†ææ–¹æ³•
- ğŸŒ æ”¯æŒå…¶ä»–è¯­è¨€ï¼ˆè‹±æ–‡ã€æ—¥æ–‡ç­‰ï¼‰
- ğŸ¨ æ”¹è¿›å¯è§†åŒ–æ•ˆæœ
- ğŸ“š è¡¥å……æ›´å¤šä½¿ç”¨ç¤ºä¾‹

---

## ğŸ“ è”ç³»æ–¹å¼ | Contact

- **GitHub Issues**: [æäº¤é—®é¢˜](https://github.com/yuzengbaao/chinese-bert-correlation/issues)
- **Email**: yuzengbaao@gmail.com
- **é¡¹ç›®ä¸»é¡µ**: https://github.com/yuzengbaao/chinese-bert-correlation

---

## ğŸ“„ å¼€æºåè®® | License

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºåè®®ã€‚

---

## ğŸ™ è‡´è°¢ | Acknowledgments

- **BERT** - Google Researchå›¢é˜Ÿçš„å¼€åˆ›æ€§å·¥ä½œ
- **Hugging Face Transformers** - ä¼˜ç§€çš„NLPå·¥å…·åº“
- **ä¸­æ–‡ç»´åŸºç™¾ç§‘** - é«˜è´¨é‡æ•°æ®æ¥æº
- **å¼€æºç¤¾åŒº** - å„ç±»ä¾èµ–åº“çš„è´¡çŒ®è€…

---

## ğŸ“Š é¡¹ç›®ç»Ÿè®¡ | Project Stats

- **ä»£ç è¡Œæ•°**: 3,600+ è¡Œ
- **æ–‡æ¡£å­—æ•°**: 50,000+ å­—
- **å¯è§†åŒ–å›¾è¡¨**: 4 å¼ é«˜æ¸…PNG
- **è®­ç»ƒæ•°æ®**: 325,537 å¥å­
- **è¯æ±‡é‡**: 10,049 è¯
- **è®­ç»ƒæ­¥æ•°**: 100,000 æ­¥
- **è®­ç»ƒæ—¶é—´**: 22.5 å°æ—¶
- **æ¨¡å‹å‚æ•°**: 48.40M å‚æ•°

---

## ğŸ”® æœªæ¥è®¡åˆ’ | Future Plans

### v1.1.0 (è®¡åˆ’ä¸­)
- [ ] æ‰©å±•åˆ°150Kè®­ç»ƒæ­¥æ•°
- [ ] æ·»åŠ Spearmanå’ŒKendallç›¸å…³æ€§åˆ†æ
- [ ] å¢åŠ å¤šGPUè®­ç»ƒæ”¯æŒ
- [ ] æä¾›é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½

### v2.0.0 (é•¿æœŸç›®æ ‡)
- [ ] æ”¯æŒè‹±æ–‡å’Œå…¶ä»–è¯­è¨€
- [ ] å®ç°åœ¨çº¿è®­ç»ƒç›‘æ§Dashboard
- [ ] é›†æˆAutoMLè‡ªåŠ¨è°ƒä¼˜
- [ ] å‘å¸ƒç ”ç©¶è®ºæ–‡

---

## âš¡ æ€§èƒ½æŒ‡æ ‡ | Performance Metrics

### è®­ç»ƒæ€§èƒ½
- **GPU**: NVIDIA RTX 3070 (8GB)
- **æ‰¹å¤§å°**: 16
- **æ­¥æ•°/ç§’**: ~1.23 steps/s
- **æ€»è®­ç»ƒæ—¶é—´**: 22.5å°æ—¶
- **GPUåˆ©ç”¨ç‡**: 92% å¹³å‡

### æ¨¡å‹æ€§èƒ½
- **å‚æ•°é‡**: 48.40M
- **æ¨ç†é€Ÿåº¦**: ~100 sentences/s (CPU)
- **æ¨¡å‹å¤§å°**: ~185 MB (.pthæ–‡ä»¶)
- **å†…å­˜å ç”¨**: ~500 MB (åŠ è½½å)

---

## ğŸŒŸ äº®ç‚¹æ€»ç»“ | Highlights

âœ¨ **é¦–ä¸ªç³»ç»ŸåŒ–ç ”ç©¶** - ä¸­æ–‡BERTè®­ç»ƒæ­¥æ•°ä¸MLMå‡†ç¡®ç‡çš„ç›¸å…³æ€§

ğŸ“Š **ä¸¥æ ¼ç»Ÿè®¡åˆ†æ** - Pearson r=0.7869ï¼Œp<0.001ï¼Œ95% CI [0.76, 0.81]

ğŸ¯ **å®ç”¨ä»·å€¼é«˜** - å¯ç”¨äºè®­ç»ƒè§„åˆ’ã€æˆæœ¬ä¼°ç®—ã€AutoMLé›†æˆ

ğŸ“š **å®Œå–„æ–‡æ¡£** - 2400+è¡ŒåŒè¯­æ–‡æ¡£ï¼Œè¦†ç›–æ‰€æœ‰ç»†èŠ‚

ğŸ’» **å¼€ç®±å³ç”¨** - 4ä¸ªç¤ºä¾‹è„šæœ¬ï¼Œ5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

ğŸ”¬ **å¯å¤ç°æ€§** - å®Œæ•´ä»£ç ã€æ•°æ®ã€è®­ç»ƒå†å²å…¨éƒ¨å…¬å¼€

---

**æ„Ÿè°¢ä½¿ç”¨æœ¬é¡¹ç›®ï¼æ¬¢è¿Starâ­å’ŒForkğŸ´**

**Thank you for using this project! Starâ­ and ForkğŸ´ are welcome!**

---

**ä¸‹è½½é™„ä»¶ | Download Assets:**
- `training_history_100k.json` - å®Œæ•´è®­ç»ƒå†å²
- `analysis_100k_result.json` - ç»Ÿè®¡åˆ†æç»“æœ

ï¼ˆæ¨¡å‹æ–‡ä»¶å› GitHubå¤§å°é™åˆ¶ï¼Œè¯·è”ç³»è·å–æˆ–è‡ªè¡Œè®­ç»ƒï¼‰
